version: '3.8'

services:
  postgres:
    image: postgres:17.2
    container_name: postgres_prod
    volumes:
      - postgres_data:/var/lib/postgresql/data
    environment:
      - POSTGRES_USER=backend
      - POSTGRES_DB=backend
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-backendpass}
      - POSTGRES_HOST_AUTH_METHOD=trust
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U backend"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    networks:
      - internal

  prometheus:
    image: prom/prometheus
    container_name: prometheus_prod
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - --config.file=/etc/prometheus/prometheus.yml
      - --storage.tsdb.path=/prometheus
      - --web.console.libraries=/etc/prometheus/console_libraries
      - --web.console.templates=/etc/prometheus/consoles
      - --storage.tsdb.retention.time=200h
      - --web.enable-lifecycle
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:9090/-/ready"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    networks:
      - internal

  grafana:
    image: grafana/grafana
    container_name: grafana_prod
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_SERVER_ROOT_URL=https://${DOMAIN_NAME}/grafana
      - GF_SERVER_SERVE_FROM_SUB_PATH=true
      - GF_SECURITY_COOKIE_SECURE=true
      - GF_SECURITY_COOKIE_SAMESITE=strict
    depends_on:
      prometheus:
        condition: service_started
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning/datasources:/etc/grafana/provisioning/datasources
      - ./grafana/provisioning/dashboards:/etc/grafana/provisioning/dashboards
      - ./grafana/dashboards:/var/lib/grafana/dashboards
    restart: unless-stopped
    networks:
      - internal

  pgadmin:
    image: dpage/pgadmin4
    container_name: pgadmin_prod
    restart: unless-stopped
    environment:
      PGADMIN_DEFAULT_EMAIL: ${PGADMIN_EMAIL:-admin@example.com}
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_PASSWORD:-admin}
      PGADMIN_CONFIG_SERVER_MODE: 'False'
    depends_on:
      postgres:
        condition: service_healthy
    volumes:
      - pgadmin_data:/var/lib/pgadmin
    networks:
      - internal

  keycloak:
    image: quay.io/keycloak/keycloak:22.0.3
    container_name: keycloak_prod
    environment:
      - KEYCLOAK_ADMIN=${KEYCLOAK_ADMIN_USER:-admin}
      - KC_HOSTNAME=${DOMAIN_NAME}
      - KC_HOSTNAME_STRICT=false
      - KC_HOSTNAME_STRICT_HTTPS=false
      - KC_HTTP_ENABLED=true
      - KC_HOSTNAME_STRICT_HTTPS=false
      - KC_HOSTNAME_STRICT_BACKCHANNEL_DYNAMIC=true
      - KEYCLOAK_ADMIN_PASSWORD=${KEYCLOAK_ADMIN_PASSWORD:-admin}
      - KC_DB=postgres
      - KC_DB_URL=jdbc:postgresql://postgres:5432/backend
      - KC_DB_USERNAME=backend
      - KC_DB_PASSWORD=${POSTGRES_PASSWORD:-backendpass}
      - KC_HOSTNAME_STRICT_HTTPS=false
      - KC_HTTP_ENABLED=true
    volumes:
      - ./keycloak/import/:/opt/keycloak/data/import/
    command:
      - start
      - --import-realm
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - internal

  minio:
    image: "minio/minio:latest"
    container_name: minio_prod
    environment:
      - MINIO_ROOT_USER=${MINIO_ROOT_USER:-minio}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD:-password}
    volumes:
      - minio_data:/data/minio
    command: minio server /data/minio --console-address ':8900'
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:9000/minio/health/live" ]
      interval: 30s
      timeout: 20s
      retries: 3
    restart: unless-stopped
    networks:
      - internal

  minio-init:
    image: minio/mc
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: [ "/bin/sh", "-c", "
      mc alias set myminio http://minio:9000 ${MINIO_ROOT_USER:-minio} ${MINIO_ROOT_PASSWORD:-password};
      mc ls myminio/trybucket || mc mb myminio/trybucket; "]
    networks:
      - internal

  nginx:
    image: nginx:latest
    container_name: nginx_prod
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.prod.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
      - /var/run/docker.sock:/tmp/docker.sock
    restart: unless-stopped
    depends_on:
      - front
      - backend
    networks:
      - internal

  front: 
    container_name: front_prod
    build:
      context: ../web/
      dockerfile: front.dockerfile
    restart: unless-stopped
    networks:
      - internal

  backend:
    build:
      context: ../backend
      dockerfile: ./backend.dockerfile
    container_name: backend_prod
    depends_on:
      postgres:
        condition: service_healthy
      keycloak:
        condition: service_started
      minio-init:
        condition: service_completed_successfully
    environment:
      - SPRING_DATASOURCE_URL=jdbc:postgresql://postgres:5432/backend
      - SPRING_DATASOURCE_USERNAME=backend
      - SPRING_DATASOURCE_PASSWORD=${POSTGRES_PASSWORD:-backendpass}
      - SERVER_PORT=8082
      - SPRING_PROFILES_ACTIVE=prod
    restart: unless-stopped
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8082/actuator/health" ]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - internal

volumes:
  postgres_data:
    driver: local
  pgadmin_data:
    driver: local
  grafana_data:
    driver: local
  prometheus_data:
    driver: local
  minio_data:
    driver: local

networks:
  internal:
    driver: bridge
